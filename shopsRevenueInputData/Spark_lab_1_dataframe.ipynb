{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.DataFrame Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 0.1 Extract link from repository **\n",
    "\n",
    "Given the repository \"input1\" which contains all the files, we build a list that contains all the files names. These latter will be useful to build our dataframe since we need the name of each City and the ID of each store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input1/paris_3.txt',\n",
       " 'input1/paris_1.txt',\n",
       " 'input1/nice.txt',\n",
       " 'input1/lyon.txt',\n",
       " 'input1/toulouse.txt',\n",
       " 'input1/marseilles_1.txt',\n",
       " 'input1/marseilles_2.txt',\n",
       " 'input1/troyes.txt',\n",
       " 'input1/rennes.txt',\n",
       " 'input1/paris_2.txt',\n",
       " 'input1/anger.txt',\n",
       " 'input1/orlean.txt',\n",
       " 'input1/nantes.txt']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypath = 'input1/'\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "link = [mypath+f for f in files]\n",
    "link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0.2 Extract City and ID from link**\n",
    "\n",
    "In this section, we made a function that takes a link to a file as input and return the correspending City and Store ID.\n",
    "The store ID is the name of the city and the number of the store, if the city has only one store, we shall take City_1 as Store ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractCityID(link):\n",
    "  # Function that compute the name of the city and its ID given the link \n",
    "  x = link.split('/')\n",
    "  y = x[len(x)-1].split('.')[0] \n",
    "  z = y.split('_')\n",
    "  if (len(z)>1):\n",
    "    City = y.split('_')[0]\n",
    "    ID = y.split('_')[1]\n",
    "    return City, y\n",
    "  else:\n",
    "    City = y.split('_')[0]\n",
    "    return City, y+'_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nice', 'nice_1')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractCityID(link[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 0.3 Create the data Frame ** \n",
    "\n",
    "To create the dataframe, we proceed by creating an RDD that contains the requested Rows and then, using an sqlContext, we create our dataframe passing the RDD as input.\n",
    "\n",
    "To do so, we start by intializing four lists. The first one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "cityId = []\n",
    "lines = []\n",
    "parts = []\n",
    "dataF = []\n",
    "cityId.append(extractCityID(link[0]))\n",
    "lines.append(sc.textFile(link[0]))\n",
    "parts.append(lines[0].map(lambda l: l.split(\" \")))\n",
    "dataF.append(parts[0].map(lambda p: Row(ID = cityId[0][1], City = cityId[0][0], Month = p[0], Revenue = int(p[1]))))\n",
    "temp = parts[0].map(lambda p: Row(ID = cityId[0][1], City = cityId[0][0], Month = p[0], Revenue = int(p[1])))\n",
    "\n",
    "dataF[0].take(10)\n",
    "for i in range(1,len(link)):\n",
    "  cityId.append(extractCityID(link[i]))\n",
    "  lines.append(sc.textFile(link[i])) \n",
    "  parts.append(lines[i].map(lambda l: l.split(\" \")))\n",
    "  dataF.append(parts[i].map(lambda p: Row(ID = cityId[i][1], City = cityId[i][0], Month = p[0], Revenue = int(p[1]))))\n",
    "  temp = temp.union(dataF[i])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+-------+\n",
      "|store_ID| City|Month|Revenue|\n",
      "+--------+-----+-----+-------+\n",
      "| paris_3|paris|  JAN|     21|\n",
      "| paris_3|paris|  FEB|     36|\n",
      "| paris_3|paris|  MAR|     24|\n",
      "| paris_3|paris|  APR|     24|\n",
      "| paris_3|paris|  MAY|     23|\n",
      "| paris_3|paris|  JUN|     25|\n",
      "| paris_3|paris|  JUL|     21|\n",
      "| paris_3|paris|  AUG|     38|\n",
      "| paris_3|paris|  SEP|     38|\n",
      "| paris_3|paris|  OCT|     38|\n",
      "| paris_3|paris|  NOV|     21|\n",
      "| paris_3|paris|  DEC|     21|\n",
      "| paris_1|paris|  JAN|     51|\n",
      "| paris_1|paris|  FEB|     21|\n",
      "| paris_1|paris|  MAR|     11|\n",
      "| paris_1|paris|  APR|     57|\n",
      "| paris_1|paris|  MAY|     55|\n",
      "| paris_1|paris|  JUN|     55|\n",
      "| paris_1|paris|  JUL|     61|\n",
      "| paris_1|paris|  AUG|     42|\n",
      "+--------+-----+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.createDataFrame(temp.map(lambda x: [x[1],x[0],x[2],x[3]]), \n",
    "                                schema=['store_ID', 'City', 'Month', 'Revenue'])    \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Average monthly income of the shop in France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Average monthly income of the shop in each city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Total revenue per city per year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Total revenue per store per year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.The store that achieves the best performance in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = sc.textFile('input1/anger.txt')\n",
    "b = a.map(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'JAN', u'13'],\n",
       " [u'FEB', u'12'],\n",
       " [u'MAR', u'14'],\n",
       " [u'APR', u'15'],\n",
       " [u'MAY', u'12'],\n",
       " [u'JUN', u'15'],\n",
       " [u'JUL', u'19'],\n",
       " [u'AUG', u'15'],\n",
       " [u'SEP', u'13'],\n",
       " [u'OCT', u'8'],\n",
       " [u'NOV', u'14'],\n",
       " [u'DEC', u'16']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
